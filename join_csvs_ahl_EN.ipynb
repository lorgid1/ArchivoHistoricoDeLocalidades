{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "591af6fa",
   "metadata": {},
   "source": [
    "# Archivo Historico de Localidades"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99cb1dcf",
   "metadata": {},
   "source": [
    "This notebook containsan an initial exploration of the files contained in the Historical Archive of Localities (Archivo historico de localidades - AHL) and joins the records that are divided by state in a single CSV."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32070321",
   "metadata": {},
   "source": [
    "## Libraries and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3463f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afc4deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True  # Imprimir notas de ejecución"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e474d6e",
   "metadata": {},
   "source": [
    "## Zipfile content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c458bc25",
   "metadata": {},
   "source": [
    "The base zip is named 'AHL.zip' and it has a compressed size of 78 megabytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34468914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory content...\n",
      "['AHL.zip']\n",
      "Tamaño:\n",
      "78.002994 Mb\n"
     ]
    }
   ],
   "source": [
    "dir_datos = 'Datos'                                      # Zip subdirectory\n",
    "nom_archivo = 'AHL.zip'                                  # Zip name\n",
    "ruta_zip_general = os.path.join(dir_datos, nom_archivo)  # Zip route\n",
    "\n",
    "\n",
    "if verbose:\n",
    "    print('Data directory content...')\n",
    "    print(os.listdir(dir_datos))\n",
    "    print('Tamaño:')\n",
    "    print(os.path.getsize(ruta_zip_general)/1_000_000, 'Mb')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6edb4239-2e89-4edf-b788-36fe882bbc62",
   "metadata": {},
   "source": [
    "General zip contains 32 zips one for each state of the Republic of Mexico. Each state zips contains 5 csv files each:\n",
    "* Habitantes.csv\n",
    "* Maestro.csv\n",
    "* Movimientos.csv\n",
    "* Res_hist.csv\n",
    "* Estructura_Archivos_AHL.pdf (Database describer, it's the same for all state zips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564ca042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir temp_ahl already exists...\n",
      "Number of files in the main zip: 32\n",
      "\n",
      "Zip content:\n",
      "\n",
      "['AHL01.zip', 'AHL02.zip', 'AHL03.zip', 'AHL04.zip', 'AHL05.zip', 'AHL06.zip', 'AHL07.zip', 'AHL08.zip', 'AHL09.zip', 'AHL10.zip', 'AHL11.zip', 'AHL12.zip', 'AHL13.zip', 'AHL14.zip', 'AHL15.zip', 'AHL16.zip', 'AHL17.zip', 'AHL18.zip', 'AHL19.zip', 'AHL20.zip', 'AHL21.zip', 'AHL22.zip', 'AHL23.zip', 'AHL24.zip', 'AHL25.zip', 'AHL26.zip', 'AHL27.zip', 'AHL28.zip', 'AHL29.zip', 'AHL30.zip', 'AHL31.zip', 'AHL32.zip']\n",
      "\n",
      "Content of the zips contained in AHL.zip:\n",
      "\n",
      "['AHL07Habitantes.csv', 'AHL07Maestro.csv', 'AHL07Movimientos.csv', 'AHL07Res_hist.csv', 'Estructura_Archivos_AHL.pdf']\n"
     ]
    }
   ],
   "source": [
    "# AHL.zip\n",
    "dir_extraccion = 'temp_ahl'  # Directory where the files will be decompressed\n",
    "\n",
    "try:\n",
    "    os.mkdir(dir_extraccion)    \n",
    "\n",
    "except FileExistsError:\n",
    "    print(f'Dir {dir_extraccion} already exists...')\n",
    "\n",
    "with ZipFile(ruta_zip_general, 'r') as zip_file:\n",
    "    lista_zips = zip_file.namelist()\n",
    "\n",
    "    # Select and extract a random zip\n",
    "    zip_estatal = lista_zips[random.randint(0, len(lista_zips) - 1)]\n",
    "    zip_file.extract(zip_estatal, dir_extraccion)\n",
    "\n",
    "\n",
    "# State zip \n",
    "nom_zip_estatal = zip_estatal[0:5]          # Zip name without extension\n",
    "dir_zip_estatal = os.path.join(dir_extraccion, nom_zip_estatal) # Dir to create\n",
    "ruta_zip_estatal = os.path.join(dir_extraccion, zip_estatal) # Zip route\n",
    "try:\n",
    "    os.mkdir(dir_zip_estatal)     \n",
    "except FileExistsError:\n",
    "    print(f'Dir {dir_zip_estatal} already exists...')\n",
    "\n",
    "\n",
    "with ZipFile(ruta_zip_estatal) as info_estatal:\n",
    "    lista_estatal = info_estatal.namelist()\n",
    "    \n",
    "    # Extract all the files\n",
    "    info_estatal.extractall(dir_zip_estatal)\n",
    "    \n",
    "if verbose:\n",
    "    print(f'Number of files in the main zip: {len(lista_zips)}', end = '\\n\\n' )\n",
    "    print('Zip content:', end = '\\n\\n')\n",
    "    print(lista_zips, end = '\\n\\n')\n",
    "    print('Content of the zips contained in AHL.zip:', end = '\\n\\n')\n",
    "    print(lista_estatal)\n",
    "\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6c3b4f0",
   "metadata": {},
   "source": [
    "Normally INEGI follows the international information sharing guidelines that use 'utf-8' as the standard encoding, but there are times when the data it offers has the 'Windows-1252' (code 'cp1252') or 'Latin-1' (code 'latin-1'). This usually happens when data is being manipulated and exported from Excel or Access. This is the case with these files. The joined files will be exported in 'utf-8'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "531c6396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the CSVs\n",
    "muestra_csvs = {}\n",
    "temas = ['Habitantes','Maestro','Movimientos','Res_hist']\n",
    "\n",
    "for tema in temas:\n",
    "    nom_csv = nom_zip_estatal + tema + '.csv'\n",
    "    ruta_csv = os.path.join(dir_zip_estatal, nom_csv)\n",
    "    \n",
    "    try:\n",
    "        with open(ruta_csv, 'r', encoding=\"cp1252\") as row: # Tried utf-8 but there where problems\n",
    "            reader = csv.reader(row)\n",
    "            header = next(reader,'unix')\n",
    "            data_sample = next(reader)\n",
    "            muestra_csvs[tema] = {key:value for key,value in zip(header, data_sample)}\n",
    "        \n",
    "        \n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f'File {nom_csv} does not exist in directory {nom_zip_estatal}...')\n",
    "\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Try a diferent coding. Mexican files normally come\",\n",
    "        \" in utf-8 o cp1252 encodings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53f3a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete temporary directory\n",
    "shutil.rmtree(dir_extraccion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d062478",
   "metadata": {},
   "source": [
    "CVE_GEOEST column appears in all tables. Inhabitants and Movements share the CLAVE Column. The rest of the columns are unique to the tables they belong to. Null values ​​exist in some columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1332ab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Column/Value of CSV Habitantes:\n",
      "('CLAVE', '45071')\n",
      "('CVE_GEOEST', '070010001')\n",
      "('EVE_CENSAL', '2010')\n",
      "('INDICE_HAB', '15160793')\n",
      "('FUENTE', 'Censo')\n",
      "('TOT_HAB', '7,515')\n",
      "('TOT_HOM', '3,664')\n",
      "('TOT_MUJ', '3,851')\n",
      "\n",
      "Sample Column/Value of CSV Maestro:\n",
      "('CVE_GEOEST', '070050095')\n",
      "('LATITUD', '')\n",
      "('LONGITUD', '')\n",
      "('ALTITUD', '')\n",
      "('CARTA_TOPO', '')\n",
      "('TIPO', 'R')\n",
      "('NOMBRE_EDO', 'Chiapas')\n",
      "('NOMBRE_MUN', 'Amatán')\n",
      "\n",
      "Sample Column/Value of CSV Movimientos:\n",
      "('CLAVE', '5298379')\n",
      "('CVE_GEOEST', '071100004')\n",
      "('INDICE', '19')\n",
      "('NOM_LOC', 'Chacampon del Carmen')\n",
      "('NOM_MUN', 'San Lucas')\n",
      "('CAT_POLI', 'Finca')\n",
      "('CAT_ADMIVA', '')\n",
      "('ORI_MODIF', 'Censo de 2020.\\nLocalidad deshabitada.')\n",
      "\n",
      "Sample Column/Value of CSV i:\n",
      "('CVE_GEOEST', '070010001'...)\n",
      "('DATOS', 'Acacoyagua-   Aca-coyahua-c, del idioma azteca; lu'...)\n",
      "('DATOS_BIBLIOGRAFIA', 'Bibliografía:(1)   Peñafiel, Antonio. Nomenclatura'...)\n"
     ]
    }
   ],
   "source": [
    "if verbose:\n",
    "    for tema in temas[:3]:\n",
    "        print(f'Sample Column/Value of CSV {tema}:')\n",
    "        for item in muestra_csvs[tema].items(): print(item)\n",
    "        print()\n",
    "    \n",
    "    print(f'Sample Column/Value of CSV {tema[3]}:')\n",
    "    for key, value in muestra_csvs[temas[3]].items(): \n",
    "        reducido = value.replace('\\n', '')[:50]\n",
    "        print(f'(\\'{key}\\', \\'{reducido}\\'...)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bae0044c",
   "metadata": {},
   "source": [
    "## Decompress CSVs bh theme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b00a700",
   "metadata": {},
   "source": [
    "In this section the state CSVs are unzipped in a folder called CSVs inside another themed subfolder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ba938cd",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f134e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_archivo(ruta_zip, dir_extraccion, archivo_extraer, verbose = False):\n",
    "    \"\"\"\n",
    "    Function to extract a file inside a zip to a given path.\n",
    "    default.\n",
    "    \n",
    "    :param zip_path: Path where zip is located.\n",
    "    :param extract_dir: Directory where the file will be extracted.\n",
    "    :param file_extract: Name of the file to extract.\n",
    "    :param verbose: Print comments in procedure.\n",
    "    :return: Returns nothing, just extract files to pc.\n",
    "\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        if not os.path.exists(dir_extraccion):\n",
    "            os.makedirs(dir_extraccion)\n",
    "            print(f'Creating directory {dir_extraccion}')\n",
    "\n",
    "    ruta_archivo_extraer = os.path.join(dir_extraccion, archivo_extraer)\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        if os.path.exists(ruta_archivo_extraer):\n",
    "            print(f'Dir {ruta_archivo_extraer} already exists, overwriting...')\n",
    "        \n",
    "        else:\n",
    "            print(f'Descompressing file {ruta_archivo_extraer}')\n",
    "\n",
    "\n",
    "    with ZipFile(ruta_zip, 'r') as zip_file:\n",
    "        zip_file.extract(archivo_extraer, dir_extraccion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58b1a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extraer_tema(dir_extraccion, tema,  dir_archivos, zipfile_list, verbose = False):\n",
    "    \"\"\"\n",
    "    Function to extract a file inside a zip to a given path.\n",
    "    \n",
    "     :param extraction_dir: Directory where the files will be extracted.\n",
    "     :param theme: Theme to be extracted, can be four:\n",
    "         Inhabitants, Movements, Master, and Res_hist\n",
    "     :param file_dir: Directory where the file zips of\n",
    "         a topic will be extracted.\n",
    "     :param zipfile_list: List of zip files where the csvs are located\n",
    "         by theme.\n",
    "     :param verbose: Print comments in procedure.\n",
    "    \n",
    "     :return: Doesn't return anything, just extracts files to pc from a theme in a\n",
    "         given directory.\n",
    "    \"\"\"\n",
    "    dir_extraccion_tema = os.path.join(dir_extraccion, tema)\n",
    "    print(f'Descompressing CSVs of {tema} in {dir_extraccion_tema}', end='... ')\n",
    "    for zip_file in zipfile_list:\n",
    "        archivo_tema = zip_file[:5] + tema +'.csv'\n",
    "        ruta_zip_estatal = os.path.join(dir_archivos, zip_file)\n",
    "        extraer_archivo(ruta_zip_estatal, dir_extraccion_tema, archivo_tema, verbose = False)\n",
    "    print(f'Extracted.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b7f0f28",
   "metadata": {},
   "source": [
    "### Extract files by theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34820a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_zip_general = 'Datos\\AHL.zip'     \n",
    "dir_extraccion_estatales = 'temp_zips_estatales' # Temporal directory\n",
    "with ZipFile(ruta_zip_general, 'r') as zip_file:\n",
    "    zip_file.extractall(dir_extraccion_estatales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ed456e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descompressing CSVs of Habitantes in CSVs\\Habitantes... Extracted.\n",
      "Descompressing CSVs of Maestro in CSVs\\Maestro... Extracted.\n",
      "Descompressing CSVs of Movimientos in CSVs\\Movimientos... Extracted.\n",
      "Descompressing CSVs of Res_hist in CSVs\\Res_hist... Extracted.\n"
     ]
    }
   ],
   "source": [
    "# Themes contained in zips are: ['Habitantes', 'Maestro', 'Movimientos', 'Res_hist']\n",
    "dir_extraccion = 'CSVs'    # Dir where themes will be extracted\n",
    "\n",
    "extraer_tema(dir_extraccion, 'Habitantes', dir_extraccion_estatales, lista_zips, verbose)\n",
    "extraer_tema(dir_extraccion, 'Maestro', dir_extraccion_estatales, lista_zips, verbose)\n",
    "extraer_tema(dir_extraccion, 'Movimientos', dir_extraccion_estatales, lista_zips, verbose)\n",
    "extraer_tema(dir_extraccion, 'Res_hist', dir_extraccion_estatales, lista_zips, verbose)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8eacaca2",
   "metadata": {},
   "source": [
    "## Join CSVs by theme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a6685a1",
   "metadata": {},
   "source": [
    "Code to join State CSVs into one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58b1ae60",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12c9e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unir_csvs(unido, a_unir, con_header = False, verbose = False):\n",
    "    \"\"\"\n",
    "    Function that reads one csv file and writes it to another.\n",
    "    \n",
    "     :param attached: File where the csv is to be attached.\n",
    "     :param to_join: File to append to the joined csv.\n",
    "     :param con_header: Name of the csv to extract can have the values of\n",
    "     :param verbose: True to print information about what you are doing.\n",
    "\n",
    "     :return: Doesn't return anything, just merges csvs.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    with open(a_unir, 'r', encoding=\"cp1252\", errors='replace') as csv_a_unir:\n",
    "        doc_reader = csv.reader(csv_a_unir)\n",
    "\n",
    "        if con_header == True:\n",
    "            with open(unido, 'w', encoding='utf-8', errors='replace') as unido:\n",
    "                doc_writer = csv.writer(unido, lineterminator='\\n')\n",
    "                header = next(doc_reader)\n",
    "                doc_writer.writerow(header)\n",
    "\n",
    "                if verbose:\n",
    "                    print(f'Added Header: {header}')\n",
    "\n",
    "                doc_writer.writerows(doc_reader)\n",
    "\n",
    "                if verbose:\n",
    "                    print(f'Rows of {a_unir} added to {unido}.')\n",
    "\n",
    "        else:\n",
    "            header = next(doc_reader)\n",
    "            with open(unido, 'a', encoding='utf-8') as unido:\n",
    "                doc_writer = csv.writer(unido, lineterminator='\\n')\n",
    "                doc_writer.writerows(doc_reader)\n",
    "                if verbose:\n",
    "                    print(f'Rows of {a_unir} joined to {unido}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64379534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unir_tema(ruta_csv, dir_carpeta, tema, verbose = False):\n",
    "    \"\"\"\n",
    "    Function to extract a file inside a zip to a given path.\n",
    "\n",
    "     :param csv_path: Path of the file where the csvs are to be joined.\n",
    "     :param folder_dir: Directory where the folder is located.\n",
    "     :param theme: Name with the folder with the csvs of the theme.\n",
    "\n",
    "     :return: Doesn't return anything, just extracts files to pc \n",
    "        from a theme in a given directory.\n",
    "    \n",
    "    \"\"\"\n",
    "    if os.path.exists(ruta_csv):\n",
    "        print(f'File {ruta_csv} already exists... deleting it')\n",
    "        os.remove(ruta_csv)\n",
    "\n",
    "    con_header = True\n",
    "    dir_tema = os.path.join(dir_carpeta, tema)\n",
    "    csvs_a_unir = os.listdir(dir_tema)\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Joining files in directory {tema}', end = '... ')\n",
    "        \n",
    "    for csv in csvs_a_unir:\n",
    "        ruta_csv_a_unir = os.path.join(dir_tema, csv)\n",
    "        #print(ruta_csv, ruta_csv_a_unir, con_header, verbose) \n",
    "  \n",
    "        unir_csvs(ruta_csv, ruta_csv_a_unir, con_header, verbose=False)\n",
    "\n",
    "        con_header = False # To only copy headers of the first CSV\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Unidos en {ruta_csv}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a5e2e14",
   "metadata": {},
   "source": [
    "### Implementación unir csvs por tema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2471a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File CSVs\\habitantes.csv already exists... deleting it\n",
      "Joining files in directory Habitantes... Unidos en CSVs\\habitantes.csv\n",
      "File CSVs\\maestro.csv already exists... deleting it\n",
      "Joining files in directory Maestro... Unidos en CSVs\\maestro.csv\n",
      "File CSVs\\movimientos.csv already exists... deleting it\n",
      "Joining files in directory Movimientos... Unidos en CSVs\\movimientos.csv\n",
      "File CSVs\\res_hist.csv already exists... deleting it\n",
      "Joining files in directory Res_hist... Unidos en CSVs\\res_hist.csv\n"
     ]
    }
   ],
   "source": [
    "# Join Theme CSVs\n",
    "# There are coding mistakes in file 25 y 32 \n",
    "# that where replaced for ? with the parameter errors = 'replace'\n",
    "# in the function unir_csvs\n",
    "\n",
    "unir_tema('CSVs\\habitantes.csv', 'CSVs', 'Habitantes', verbose)\n",
    "unir_tema('CSVs\\maestro.csv', 'CSVs', 'Maestro', verbose)\n",
    "unir_tema('CSVs\\movimientos.csv', 'CSVs', 'Movimientos', verbose)\n",
    "unir_tema(r'CSVs\\res_hist.csv', 'CSVs', 'Res_hist', verbose) # tiene r antes del string para que\n",
    "                                                             # /r se interprete bien\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34363825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de habitantes.csv: 98.951205 megabytes\n",
      "Numero de registros: 2138702\n",
      "Tamaño de maestro.csv: 33.13731 megabytes\n",
      "Numero de registros: 409446\n",
      "Tamaño de movimientos.csv: 221.355535 megabytes\n",
      "Numero de registros: 3565344\n",
      "Tamaño de res_hist.csv: 13.379794 megabytes\n",
      "Numero de registros: 198847\n"
     ]
    }
   ],
   "source": [
    "# Resulting file information\n",
    "for tema in temas:\n",
    "    csv_general = tema.lower() + '.csv'\n",
    "    ruta = os.path.join('CSVs', csv_general)\n",
    "    print(f'Tamaño de {csv_general}:', end = ' ')\n",
    "    print(os.stat(ruta).st_size / 1000000, 'megabytes')\n",
    "    with open(ruta, 'r') as csv_tema:\n",
    "        num_lineas = len(csv_tema.readlines()) - 1\n",
    "        print(f'Numero de registros: {num_lineas}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06edca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete directory with State Zips\n",
    "shutil.rmtree(dir_extraccion_estatales)\n",
    "\n",
    "# Delete directory with State CSVs\n",
    "shutil.rmtree('CSVs/Habitantes/')\n",
    "shutil.rmtree('CSVs/Maestro/')\n",
    "shutil.rmtree('CSVs/Movimientos/')\n",
    "shutil.rmtree('CSVs/Res_hist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad070f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "6afe7e267b9ba88bffeda2619d27c3cb5e96fca6caeba51772f3019486e6bf34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
